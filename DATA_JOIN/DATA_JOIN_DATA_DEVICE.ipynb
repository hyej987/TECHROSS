{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA_JOIN_DATA_DEVICE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNulR59L+xebIUUuNSPI0Xn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnJungChan/TECHLOSS_SIGNLAB/blob/main/DATA/DATA_JOIN_DATA_DEVICE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패키지 로딩"
      ],
      "metadata": {
        "id": "7TkllpOKddkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q7YedWEZHhA",
        "outputId": "ffd9d244-a138-46a0-a1c9-207c3a2d9cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로딩"
      ],
      "metadata": {
        "id": "kC5bYeY7dgxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ECU = pd.read_csv('/content/gdrive/MyDrive/DB/ECU.csv')\n",
        "ANU = pd.read_csv('/content/gdrive/MyDrive/DB/ANU.csv')\n",
        "TSU = pd.read_csv('/content/gdrive/MyDrive/DB/TSU.csv')\n",
        "PMU = pd.read_csv('/content/gdrive/MyDrive/DB/PMU.csv')\n",
        "DATA_DEVICE = pd.read_csv('/content/gdrive/MyDrive/DB/DATA_DEVICE.csv')\n",
        "DATA = pd.read_csv('/content/gdrive/MyDrive/DB/DATA.csv')"
      ],
      "metadata": {
        "id": "Xz-OHgSOahZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANU,TSU,PMU,ECU JOIN DATA_DEVICE\n",
        "\n",
        "- DATA_DEVICE를 DEVICETYPE별로 4개로 나눈후, 각각을 ECU, ANU, TSU, PMU에 INNER JOIN을 실시하였음\n",
        "\n",
        "- 하나의 DATA_DEVICE 테이블을 4개로 나누는 작업임."
      ],
      "metadata": {
        "id": "qn2gXpFxa8dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ECU['DDKEY'] = ECU['SHIP_ID'] + \"_\" + ECU['SECTION'].astype(str) + \"_\" + ECU['D_INDEX'].astype(str) + \"_\" + ECU['DEVICE_ID'].astype(str)\n",
        "ANU['DDKEY'] = ANU['SHIP_ID'] + \"_\" + ANU['SECTION'].astype(str) + \"_\" + ANU['D_INDEX'].astype(str) + \"_\" + ANU['DEVICE_ID'].astype(str)\n",
        "TSU['DDKEY'] = TSU['SHIP_ID'] + \"_\" + TSU['SECTION'].astype(str) + \"_\" + TSU['D_INDEX'].astype(str) + \"_\" + TSU['DEVICE_ID'].astype(str)\n",
        "PMU['DDKEY'] = PMU['SHIP_ID'] + \"_\" + PMU['SECTION'].astype(str) + \"_\" + PMU['D_INDEX'].astype(str) + \"_\" + PMU['DEVICE_ID'].astype(str)\n",
        "DATA_DEVICE['DDKEY'] = DATA_DEVICE['SHIP_ID'] + \"_\" + DATA_DEVICE['SECTION'].astype(str) + \"_\" + DATA_DEVICE['D_INDEX'].astype(str) + \"_\" + DATA_DEVICE['DEVICE_ID'].astype(str)"
      ],
      "metadata": {
        "id": "mJuHUPizbC96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DEVICE_ECU=DATA_DEVICE.loc[DATA_DEVICE['DEVICETYPE']==1,:]\n",
        "DATA_DEVICE_ANU=DATA_DEVICE.loc[DATA_DEVICE['DEVICETYPE']==2,:]\n",
        "DATA_DEVICE_TSU=DATA_DEVICE.loc[DATA_DEVICE['DEVICETYPE']==3,:]\n",
        "DATA_DEVICE_PMU=DATA_DEVICE.loc[DATA_DEVICE['DEVICETYPE']==4,:]"
      ],
      "metadata": {
        "id": "9-TXZ3CocmXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DDECU = pd.merge(ECU,DATA_DEVICE_ECU, how = 'inner', on = 'DDKEY')\n",
        "DDECU=DDECU.drop(columns = ['DEVICE_ID_y','D_INDEX_y','SHIP_ID_y','SYSTEM_y','SECTION_y','DDKEY'])\n",
        "DDECU=DDECU.rename(columns = {'SHIP_ID_x' : 'SHIP_ID', 'D_INDEX_x' : 'D_INDEX', 'DEVICE_ID_x' : 'DEVICE_ID', 'SYSTEM_x' : 'SYSTEM', 'SECTION_x':'SECTION'})\n",
        "\n",
        "DDANU = pd.merge(ANU,DATA_DEVICE_ANU, how = 'inner', on = 'DDKEY')\n",
        "DDANU=DDANU.drop(columns = ['DEVICE_ID_y','D_INDEX_y','SHIP_ID_y','SYSTEM_y','SECTION_y','DDKEY'])\n",
        "DDANU=DDANU.rename(columns = {'SHIP_ID_x' : 'SHIP_ID', 'D_INDEX_x' : 'D_INDEX', 'DEVICE_ID_x' : 'DEVICE_ID', 'SYSTEM_x' : 'SYSTEM', 'SECTION_x':'SECTION'})\n",
        "\n",
        "DDPMU = pd.merge(PMU,DATA_DEVICE_PMU, how = 'inner', on = 'DDKEY')\n",
        "DDPMU=DDPMU.drop(columns = ['DEVICE_ID_y','D_INDEX_y','SHIP_ID_y','SYSTEM_y','SECTION_y','DDKEY'])\n",
        "DDPMU=DDPMU.rename(columns = {'SHIP_ID_x' : 'SHIP_ID', 'D_INDEX_x' : 'D_INDEX', 'DEVICE_ID_x' : 'DEVICE_ID', 'SYSTEM_x' : 'SYSTEM', 'SECTION_x':'SECTION'})\n",
        "\n",
        "DDTSU = pd.merge(TSU,DATA_DEVICE_TSU, how = 'inner', on = 'DDKEY')\n",
        "DDTSU=DDTSU.drop(columns = ['DEVICE_ID_y','D_INDEX_y','SHIP_ID_y','SYSTEM_y','SECTION_y','DDKEY'])\n",
        "DDTSU=DDTSU.rename(columns = {'SHIP_ID_x' : 'SHIP_ID', 'D_INDEX_x' : 'D_INDEX', 'DEVICE_ID_x' : 'DEVICE_ID', 'SYSTEM_x' : 'SYSTEM', 'SECTION_x':'SECTION'})"
      ],
      "metadata": {
        "id": "-_igzEJVbByg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEVICE_ID별 테이블 분할\n",
        "\n",
        "- DATA_DEVICE테이블을 DEVICETYPE별로 4개로 나눈 각각의 테이블을 ECU, ANU, PMU, TSU 테이블과 병합시켰음\n",
        "\n",
        "- 병합시킨 4개의 테이블에 대해서, 다시 각각의 DEVICE_ID별로 테이블을 나눠서, ECU 테이블은 9개, ANU 테이블은 8개, PMU 테이블은 10개, TSU 테이블은 2개로 나눔"
      ],
      "metadata": {
        "id": "peT0vns8f4Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(DDECU['DEVICE_ID'].unique())\n",
        "print(DDANU['DEVICE_ID'].unique())\n",
        "print(DDPMU['DEVICE_ID'].unique())\n",
        "print(DDTSU['DEVICE_ID'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiN24CTXf8KK",
        "outputId": "c49702b1-fa07-4ae1-a9c3-569edb21dd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5 6 7 8 9]\n",
            "[1 2 3 4 5 6 7 8]\n",
            "[ 1  2  3  4  5  6  7  8  9 10]\n",
            "[1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DDECU_1 = DDECU.loc[DDECU['DEVICE_ID'] == 1,:]\n",
        "DDECU_1['KEY']=DDECU_1['SHIP_ID'] + \"_\" + DDECU_1['SECTION'].astype(str) + \"_\" + DDECU_1['OP_INDEX'].astype(str) + \"_\" + DDECU_1['DATA_INDEX'].astype(str)\n",
        "DDECU_1 = DDECU_1.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_1=DDECU_1.drop_duplicates(['KEY'])\n",
        "DDECU_1.rename(columns = lambda x: \"ECU1_\" + x, inplace = True)\n",
        "DDECU_1.rename(columns = {'ECU1_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_2 = DDECU.loc[DDECU['DEVICE_ID'] == 2,:]\n",
        "DDECU_2['KEY']=DDECU_2['SHIP_ID'] + \"_\" + DDECU_2['SECTION'].astype(str) + \"_\" + DDECU_2['OP_INDEX'].astype(str) + \"_\" + DDECU_2['DATA_INDEX'].astype(str)\n",
        "DDECU_2 = DDECU_2.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_2=DDECU_2.drop_duplicates(['KEY'])\n",
        "DDECU_2.rename(columns = lambda x: \"ECU2_\" + x, inplace = True)\n",
        "DDECU_2.rename(columns = {'ECU2_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_3 = DDECU.loc[DDECU['DEVICE_ID'] == 3,:]\n",
        "DDECU_3['KEY']=DDECU_3['SHIP_ID'] + \"_\" + DDECU_3['SECTION'].astype(str) + \"_\" + DDECU_3['OP_INDEX'].astype(str) + \"_\" + DDECU_3['DATA_INDEX'].astype(str)\n",
        "DDECU_3 = DDECU_3.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_3=DDECU_3.drop_duplicates(['KEY'])\n",
        "DDECU_3.rename(columns = lambda x: \"ECU3_\" + x, inplace = True)\n",
        "DDECU_3.rename(columns = {'ECU3_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_4 = DDECU.loc[DDECU['DEVICE_ID'] == 4,:]\n",
        "DDECU_4['KEY']=DDECU_4['SHIP_ID'] + \"_\" + DDECU_4['SECTION'].astype(str) + \"_\" + DDECU_4['OP_INDEX'].astype(str) + \"_\" + DDECU_4['DATA_INDEX'].astype(str)\n",
        "DDECU_4 = DDECU_4.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_4=DDECU_4.drop_duplicates(['KEY'])\n",
        "DDECU_4.rename(columns = lambda x: \"ECU4_\" + x, inplace = True)\n",
        "DDECU_4.rename(columns = {'ECU4_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_5 = DDECU.loc[DDECU['DEVICE_ID'] == 5,:]\n",
        "DDECU_5['KEY']=DDECU_5['SHIP_ID'] + \"_\" + DDECU_5['SECTION'].astype(str) + \"_\" + DDECU_5['OP_INDEX'].astype(str) + \"_\" + DDECU_5['DATA_INDEX'].astype(str)\n",
        "DDECU_5 = DDECU_5.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_5=DDECU_5.drop_duplicates(['KEY'])\n",
        "DDECU_5.rename(columns = lambda x: \"ECU5_\" + x, inplace = True)\n",
        "DDECU_5.rename(columns = {'ECU5_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_6 = DDECU.loc[DDECU['DEVICE_ID'] == 6,:]\n",
        "DDECU_6['KEY']=DDECU_6['SHIP_ID'] + \"_\" + DDECU_6['SECTION'].astype(str) + \"_\" + DDECU_6['OP_INDEX'].astype(str) + \"_\" + DDECU_6['DATA_INDEX'].astype(str)\n",
        "DDECU_6 = DDECU_6.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_6=DDECU_6.drop_duplicates(['KEY'])\n",
        "DDECU_6.rename(columns = lambda x: \"ECU6_\" + x, inplace = True)\n",
        "DDECU_6.rename(columns = {'ECU6_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_7 = DDECU.loc[DDECU['DEVICE_ID'] == 7,:]\n",
        "DDECU_7['KEY']=DDECU_7['SHIP_ID'] + \"_\" + DDECU_7['SECTION'].astype(str) + \"_\" + DDECU_7['OP_INDEX'].astype(str) + \"_\" + DDECU_7['DATA_INDEX'].astype(str)\n",
        "DDECU_7 = DDECU_7.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_7=DDECU_7.drop_duplicates(['KEY'])\n",
        "DDECU_7.rename(columns = lambda x: \"ECU7_\" + x, inplace = True)\n",
        "DDECU_7.rename(columns = {'ECU7_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_8 = DDECU.loc[DDECU['DEVICE_ID'] == 8,:]\n",
        "DDECU_8['KEY']=DDECU_8['SHIP_ID'] + \"_\" + DDECU_8['SECTION'].astype(str) + \"_\" + DDECU_8['OP_INDEX'].astype(str) + \"_\" + DDECU_8['DATA_INDEX'].astype(str)\n",
        "DDECU_8 = DDECU_8.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_8=DDECU_8.drop_duplicates(['KEY'])\n",
        "DDECU_8.rename(columns = lambda x: \"ECU8_\" + x, inplace = True)\n",
        "DDECU_8.rename(columns = {'ECU8_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDECU_9 = DDECU.loc[DDECU['DEVICE_ID'] == 9,:]\n",
        "DDECU_9['KEY']=DDECU_9['SHIP_ID'] + \"_\" + DDECU_9['SECTION'].astype(str) + \"_\" + DDECU_9['OP_INDEX'].astype(str) + \"_\" + DDECU_9['DATA_INDEX'].astype(str)\n",
        "DDECU_9 = DDECU_9.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDECU_9=DDECU_9.drop_duplicates(['KEY'])\n",
        "DDECU_9.rename(columns = lambda x: \"ECU9_\" + x, inplace = True)\n",
        "DDECU_9.rename(columns = {'ECU9_KEY' : 'KEY'},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1j_4XlygcfI",
        "outputId": "8740e300-5fe9-4d8c-844d-8c32445341ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DDANU_1 = DDANU.loc[DDANU['DEVICE_ID'] == 1,:]\n",
        "DDANU_1['KEY']=DDANU_1['SHIP_ID'] + \"_\" + DDANU_1['SECTION'].astype(str) + \"_\" + DDANU_1['OP_INDEX'].astype(str) + \"_\" + DDANU_1['DATA_INDEX'].astype(str)\n",
        "DDANU_1 = DDANU_1.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_1=DDANU_1.drop_duplicates(['KEY'])\n",
        "DDANU_1.rename(columns = lambda x: \"ANU1_\" + x, inplace = True)\n",
        "DDANU_1.rename(columns = {'ANU1_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_2 = DDANU.loc[DDANU['DEVICE_ID'] == 2,:]\n",
        "DDANU_2['KEY']=DDANU_2['SHIP_ID'] + \"_\" + DDANU_2['SECTION'].astype(str) + \"_\" + DDANU_2['OP_INDEX'].astype(str) + \"_\" + DDANU_2['DATA_INDEX'].astype(str)\n",
        "DDANU_2 = DDANU_2.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_2=DDANU_2.drop_duplicates(['KEY'])\n",
        "DDANU_2.rename(columns = lambda x: \"ANU2_\" + x, inplace = True)\n",
        "DDANU_2.rename(columns = {'ANU2_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_3 = DDANU.loc[DDANU['DEVICE_ID'] == 3,:]\n",
        "DDANU_3['KEY']=DDANU_3['SHIP_ID'] + \"_\" + DDANU_3['SECTION'].astype(str) + \"_\" + DDANU_3['OP_INDEX'].astype(str) + \"_\" + DDANU_3['DATA_INDEX'].astype(str)\n",
        "DDANU_3 = DDANU_3.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_3=DDANU_3.drop_duplicates(['KEY'])\n",
        "DDANU_3.rename(columns = lambda x: \"ANU3_\" + x, inplace = True)\n",
        "DDANU_3.rename(columns = {'ANU3_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_4 = DDANU.loc[DDANU['DEVICE_ID'] == 4,:]\n",
        "DDANU_4['KEY']=DDANU_4['SHIP_ID'] + \"_\" + DDANU_4['SECTION'].astype(str) + \"_\" + DDANU_4['OP_INDEX'].astype(str) + \"_\" + DDANU_4['DATA_INDEX'].astype(str)\n",
        "DDANU_4 = DDANU_4.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_4=DDANU_4.drop_duplicates(['KEY'])\n",
        "DDANU_4.rename(columns = lambda x: \"ANU4_\" + x, inplace = True)\n",
        "DDANU_4.rename(columns = {'ANU4_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_5 = DDANU.loc[DDANU['DEVICE_ID'] == 5,:]\n",
        "DDANU_5['KEY']=DDANU_5['SHIP_ID'] + \"_\" + DDANU_5['SECTION'].astype(str) + \"_\" + DDANU_5['OP_INDEX'].astype(str) + \"_\" + DDANU_5['DATA_INDEX'].astype(str)\n",
        "DDANU_5 = DDANU_5.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_5=DDANU_5.drop_duplicates(['KEY'])\n",
        "DDANU_5.rename(columns = lambda x: \"ANU5_\" + x, inplace = True)\n",
        "DDANU_5.rename(columns = {'ANU5_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_6 = DDANU.loc[DDANU['DEVICE_ID'] == 6,:]\n",
        "DDANU_6['KEY']=DDANU_6['SHIP_ID'] + \"_\" + DDANU_6['SECTION'].astype(str) + \"_\" + DDANU_6['OP_INDEX'].astype(str) + \"_\" + DDANU_6['DATA_INDEX'].astype(str)\n",
        "DDANU_6 = DDANU_6.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_6=DDANU_6.drop_duplicates(['KEY'])\n",
        "DDANU_6.rename(columns = lambda x: \"ANU6_\" + x, inplace = True)\n",
        "DDANU_6.rename(columns = {'ANU6_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_7 = DDANU.loc[DDANU['DEVICE_ID'] == 7,:]\n",
        "DDANU_7['KEY']=DDANU_7['SHIP_ID'] + \"_\" + DDANU_7['SECTION'].astype(str) + \"_\" + DDANU_7['OP_INDEX'].astype(str) + \"_\" + DDANU_7['DATA_INDEX'].astype(str)\n",
        "DDANU_7 = DDANU_7.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_7=DDANU_7.drop_duplicates(['KEY'])\n",
        "DDANU_7.rename(columns = lambda x: \"ANU7_\" + x, inplace = True)\n",
        "DDANU_7.rename(columns = {'ANU7_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDANU_8 = DDANU.loc[DDANU['DEVICE_ID'] == 8,:]\n",
        "DDANU_8['KEY']=DDANU_8['SHIP_ID'] + \"_\" + DDANU_8['SECTION'].astype(str) + \"_\" + DDANU_8['OP_INDEX'].astype(str) + \"_\" + DDANU_8['DATA_INDEX'].astype(str)\n",
        "DDANU_8 = DDANU_8.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDANU_8=DDANU_8.drop_duplicates(['KEY'])\n",
        "DDANU_8.rename(columns = lambda x: \"ANU8_\" + x, inplace = True)\n",
        "DDANU_8.rename(columns = {'ANU8_KEY' : 'KEY'},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8LNR3O2ju-x",
        "outputId": "fb97dc37-0345-4d42-acc4-625a91dab3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DDPMU_1 = DDPMU.loc[DDPMU['DEVICE_ID'] == 1,:]\n",
        "DDPMU_1['KEY']=DDPMU_1['SHIP_ID'] + \"_\" + DDPMU_1['SECTION'].astype(str) + \"_\" + DDPMU_1['OP_INDEX'].astype(str) + \"_\" + DDPMU_1['DATA_INDEX'].astype(str)\n",
        "DDPMU_1 = DDPMU_1.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_1=DDPMU_1.drop_duplicates(['KEY'])\n",
        "DDPMU_1.rename(columns = lambda x: \"PMU1_\" + x, inplace = True)\n",
        "DDPMU_1.rename(columns = {'PMU1_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_2 = DDPMU.loc[DDPMU['DEVICE_ID'] == 2,:]\n",
        "DDPMU_2['KEY']=DDPMU_2['SHIP_ID'] + \"_\" + DDPMU_2['SECTION'].astype(str) + \"_\" + DDPMU_2['OP_INDEX'].astype(str) + \"_\" + DDPMU_2['DATA_INDEX'].astype(str)\n",
        "DDPMU_2 = DDPMU_2.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_2=DDPMU_2.drop_duplicates(['KEY'])\n",
        "DDPMU_2.rename(columns = lambda x: \"PMU2_\" + x, inplace = True)\n",
        "DDPMU_2.rename(columns = {'PMU2_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_3 = DDPMU.loc[DDPMU['DEVICE_ID'] == 3,:]\n",
        "DDPMU_3['KEY']=DDPMU_3['SHIP_ID'] + \"_\" + DDPMU_3['SECTION'].astype(str) + \"_\" + DDPMU_3['OP_INDEX'].astype(str) + \"_\" + DDPMU_3['DATA_INDEX'].astype(str)\n",
        "DDPMU_3 = DDPMU_3.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_3=DDPMU_3.drop_duplicates(['KEY'])\n",
        "DDPMU_3.rename(columns = lambda x: \"PMU3_\" + x, inplace = True)\n",
        "DDPMU_3.rename(columns = {'PMU3_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_4 = DDPMU.loc[DDPMU['DEVICE_ID'] == 4,:]\n",
        "DDPMU_4['KEY']=DDPMU_4['SHIP_ID'] + \"_\" + DDPMU_4['SECTION'].astype(str) + \"_\" + DDPMU_4['OP_INDEX'].astype(str) + \"_\" + DDPMU_4['DATA_INDEX'].astype(str)\n",
        "DDPMU_4 = DDPMU_4.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_4=DDPMU_4.drop_duplicates(['KEY'])\n",
        "DDPMU_4.rename(columns = lambda x: \"PMU4_\" + x, inplace = True)\n",
        "DDPMU_4.rename(columns = {'PMU4_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_5 = DDPMU.loc[DDPMU['DEVICE_ID'] == 5,:]\n",
        "DDPMU_5['KEY']=DDPMU_5['SHIP_ID'] + \"_\" + DDPMU_5['SECTION'].astype(str) + \"_\" + DDPMU_5['OP_INDEX'].astype(str) + \"_\" + DDPMU_5['DATA_INDEX'].astype(str)\n",
        "DDPMU_5 = DDPMU_5.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_5=DDPMU_5.drop_duplicates(['KEY'])\n",
        "DDPMU_5.rename(columns = lambda x: \"PMU5_\" + x, inplace = True)\n",
        "DDPMU_5.rename(columns = {'PMU5_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_6 = DDPMU.loc[DDPMU['DEVICE_ID'] == 6,:]\n",
        "DDPMU_6['KEY']=DDPMU_6['SHIP_ID'] + \"_\" + DDPMU_6['SECTION'].astype(str) + \"_\" + DDPMU_6['OP_INDEX'].astype(str) + \"_\" + DDPMU_6['DATA_INDEX'].astype(str)\n",
        "DDPMU_6 = DDPMU_6.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_6=DDPMU_6.drop_duplicates(['KEY'])\n",
        "DDPMU_6.rename(columns = lambda x: \"PMU6_\" + x, inplace = True)\n",
        "DDPMU_6.rename(columns = {'PMU6_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_7 = DDPMU.loc[DDPMU['DEVICE_ID'] == 7,:]\n",
        "DDPMU_7['KEY']=DDPMU_7['SHIP_ID'] + \"_\" + DDPMU_7['SECTION'].astype(str) + \"_\" + DDPMU_7['OP_INDEX'].astype(str) + \"_\" + DDPMU_7['DATA_INDEX'].astype(str)\n",
        "DDPMU_7 = DDPMU_7.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_7=DDPMU_7.drop_duplicates(['KEY'])\n",
        "DDPMU_7.rename(columns = lambda x: \"PMU7_\" + x, inplace = True)\n",
        "DDPMU_7.rename(columns = {'PMU7_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_8 = DDPMU.loc[DDPMU['DEVICE_ID'] == 8,:]\n",
        "DDPMU_8['KEY']=DDPMU_8['SHIP_ID'] + \"_\" + DDPMU_8['SECTION'].astype(str) + \"_\" + DDPMU_8['OP_INDEX'].astype(str) + \"_\" + DDPMU_8['DATA_INDEX'].astype(str)\n",
        "DDPMU_8 = DDPMU_8.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_8=DDPMU_8.drop_duplicates(['KEY'])\n",
        "DDPMU_8.rename(columns = lambda x: \"PMU8_\" + x, inplace = True)\n",
        "DDPMU_8.rename(columns = {'PMU8_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_9 = DDPMU.loc[DDPMU['DEVICE_ID'] == 9,:]\n",
        "DDPMU_9['KEY']=DDPMU_9['SHIP_ID'] + \"_\" + DDPMU_9['SECTION'].astype(str) + \"_\" + DDPMU_9['OP_INDEX'].astype(str) + \"_\" + DDPMU_9['DATA_INDEX'].astype(str)\n",
        "DDPMU_9 = DDPMU_9.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_9=DDPMU_9.drop_duplicates(['KEY'])\n",
        "DDPMU_9.rename(columns = lambda x: \"PMU9_\" + x, inplace = True)\n",
        "DDPMU_9.rename(columns = {'PMU9_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDPMU_10 = DDPMU.loc[DDPMU['DEVICE_ID'] == 10,:]\n",
        "DDPMU_10['KEY']=DDPMU_10['SHIP_ID'] + \"_\" + DDPMU_10['SECTION'].astype(str) + \"_\" + DDPMU_10['OP_INDEX'].astype(str) + \"_\" + DDPMU_10['DATA_INDEX'].astype(str)\n",
        "DDPMU_10 = DDPMU_10.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDPMU_10=DDPMU_10.drop_duplicates(['KEY'])\n",
        "DDPMU_10.rename(columns = lambda x: \"PMU10_\" + x, inplace = True)\n",
        "DDPMU_10.rename(columns = {'PMU10_KEY' : 'KEY'},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74-Iv4q0kXH4",
        "outputId": "c6c2b1e4-4b9e-48c0-c984-085989b50114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DDTSU_1 = DDTSU.loc[DDTSU['DEVICE_ID'] == 1,:]\n",
        "DDTSU_1['KEY']=DDTSU_1['SHIP_ID'] + \"_\" + DDTSU_1['SECTION'].astype(str) + \"_\" + DDTSU_1['OP_INDEX'].astype(str) + \"_\" + DDTSU_1['DATA_INDEX'].astype(str)\n",
        "DDTSU_1 = DDTSU_1.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDTSU_1=DDTSU_1.drop_duplicates(['KEY'])\n",
        "DDTSU_1.rename(columns = lambda x: \"TSU1_\" + x, inplace = True)\n",
        "DDTSU_1.rename(columns = {'TSU1_KEY' : 'KEY'},inplace=True)\n",
        "\n",
        "DDTSU_2 = DDTSU.loc[DDTSU['DEVICE_ID'] == 2,:]\n",
        "DDTSU_2['KEY']=DDTSU_2['SHIP_ID'] + \"_\" + DDTSU_2['SECTION'].astype(str) + \"_\" + DDTSU_2['OP_INDEX'].astype(str) + \"_\" + DDTSU_2['DATA_INDEX'].astype(str)\n",
        "DDTSU_2 = DDTSU_2.drop(columns = ['SHIP_ID', 'D_INDEX', 'DEVICE_ID', 'SYSTEM', 'SECTION', 'DATA_INDEX', 'OP_INDEX', 'DEVICETYPE'])\n",
        "DDTSU_2=DDTSU_2.drop_duplicates(['KEY'])\n",
        "DDTSU_2.rename(columns = lambda x: \"TSU2_\" + x, inplace = True)\n",
        "DDTSU_2.rename(columns = {'TSU2_KEY' : 'KEY'},inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ5lrlaEk8Uy",
        "outputId": "d2316517-2c1d-4ef1-b03a-5ccee28d707f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA JOIN DATA_DEVICE\n",
        "\n",
        "- ECU 테이블은 9개, ANU 테이블은 8개, PMU 테이블은 10개, TSU 테이블은 2개로 나누었음\n",
        "\n",
        "- 이 각각의 테이블을 LEFT JOIN을 기준으로 열을 늘리는 방식으로 테이블을 늘림\n",
        "\n",
        "- LEFT JOIN의 기준은 DATA 테이블이며, 결론적으로 행의수는 DATA테이블과 똑같음. 다만, 열의 갯수가 매우 많이 늘어나는 현상이 발생.\n",
        "\n",
        "- 열이 많이 늘어나는 이유는 DATA_DEVICE를 29개의 테이블로 나눈 후, LEFT JOIN을 시켰기 때문임."
      ],
      "metadata": {
        "id": "NSgUvm4hBADq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA['KEY']=DATA['SHIP_ID'] + \"_\" + DATA['SECTION'].astype(str) + \"_\" + DATA['OP_INDEX'].astype(str) + \"_\" + DATA['DATA_INDEX'].astype(str)"
      ],
      "metadata": {
        "id": "g-5OOUQQmR5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA1=pd.merge(DATA,DDECU_1,how='left', on = 'KEY')\n",
        "DATA2=pd.merge(DATA,DDECU_2,how='left', on = 'KEY')\n",
        "DATA3=pd.merge(DATA,DDECU_3,how='left', on = 'KEY')\n",
        "DATA4=pd.merge(DATA,DDECU_4,how='left', on = 'KEY')\n",
        "DATA5=pd.merge(DATA,DDECU_5,how='left', on = 'KEY')\n",
        "DATA6=pd.merge(DATA,DDECU_6,how='left', on = 'KEY')\n",
        "DATA7=pd.merge(DATA,DDECU_7,how='left', on = 'KEY')\n",
        "DATA8=pd.merge(DATA,DDECU_8,how='left', on = 'KEY')\n",
        "DATA9=pd.merge(DATA,DDECU_9,how='left', on = 'KEY')\n",
        "\n",
        "DATA11=pd.merge(DATA,DDANU_1,how='left', on = 'KEY')\n",
        "DATA12=pd.merge(DATA,DDANU_2,how='left', on = 'KEY')\n",
        "DATA13=pd.merge(DATA,DDANU_3,how='left', on = 'KEY')\n",
        "DATA14=pd.merge(DATA,DDANU_4,how='left', on = 'KEY')\n",
        "DATA15=pd.merge(DATA,DDANU_5,how='left', on = 'KEY')\n",
        "DATA16=pd.merge(DATA,DDANU_6,how='left', on = 'KEY')\n",
        "DATA17=pd.merge(DATA,DDANU_7,how='left', on = 'KEY')\n",
        "DATA18=pd.merge(DATA,DDANU_8,how='left', on = 'KEY')\n",
        "\n",
        "\n",
        "DATA21=pd.merge(DATA,DDPMU_1,how='left', on = 'KEY')\n",
        "DATA22=pd.merge(DATA,DDPMU_2,how='left', on = 'KEY')\n",
        "DATA23=pd.merge(DATA,DDPMU_3,how='left', on = 'KEY')\n",
        "DATA24=pd.merge(DATA,DDPMU_4,how='left', on = 'KEY')\n",
        "DATA25=pd.merge(DATA,DDPMU_5,how='left', on = 'KEY')\n",
        "DATA26=pd.merge(DATA,DDPMU_6,how='left', on = 'KEY')\n",
        "DATA27=pd.merge(DATA,DDPMU_7,how='left', on = 'KEY')\n",
        "DATA28=pd.merge(DATA,DDPMU_8,how='left', on = 'KEY')\n",
        "DATA29=pd.merge(DATA,DDPMU_9,how='left', on = 'KEY')\n",
        "DATA210=pd.merge(DATA,DDPMU_10,how='left', on = 'KEY')\n",
        "\n",
        "DATA31=pd.merge(DATA,DDTSU_1,how='left', on = 'KEY')\n",
        "DATA32=pd.merge(DATA,DDTSU_2,how='left', on = 'KEY')\n",
        "\n",
        "\n",
        "DATA1 = DATA1.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA2 = DATA2.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA3 = DATA3.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA4 = DATA4.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA5 = DATA5.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA6 = DATA6.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA7 = DATA7.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA8 = DATA8.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA9 = DATA9.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "\n",
        "DATA11 = DATA11.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA12 = DATA12.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA13 = DATA13.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA14 = DATA14.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA15 = DATA15.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA16 = DATA16.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA17 = DATA17.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA18 = DATA18.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "\n",
        "DATA21 = DATA21.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA22 = DATA22.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA23 = DATA23.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA24 = DATA24.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA25 = DATA25.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA26 = DATA26.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA27 = DATA27.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA28 = DATA28.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA29 = DATA29.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA210 = DATA210.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "\n",
        "DATA31 = DATA31.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])\n",
        "DATA32 = DATA32.drop(columns = ['OP_INDEX',\t'DATA_INDEX',\t'DATA_TIME',\t'CSU',\t'STS',\t'FTS',\t'FMU',\t'TRO',\t'ANU',\t'RATE',\t'CURRENT',\t'VOLTAGE'\t,'TRO_COUNT',\t'SHIP_ID',\t'SYSTEM',\t'SECTION',\t'KEY'])"
      ],
      "metadata": {
        "id": "-DZlY7k5lQTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DATA_DEVICE=pd.concat([DATA,\n",
        "           DATA1,\n",
        "           DATA2,\n",
        "           DATA3,\n",
        "           DATA4,\n",
        "           DATA5,\n",
        "           DATA6,\n",
        "           DATA7,\n",
        "           DATA8,\n",
        "           DATA9,\n",
        "           DATA11,\n",
        "           DATA12,\n",
        "           DATA13,\n",
        "           DATA14,\n",
        "           DATA15,\n",
        "           DATA16,\n",
        "           DATA17,\n",
        "           DATA18,\n",
        "           DATA21,\n",
        "           DATA22,\n",
        "           DATA23,\n",
        "           DATA24,\n",
        "           DATA25,\n",
        "           DATA26,\n",
        "           DATA27,\n",
        "           DATA28,\n",
        "           DATA29,\n",
        "           DATA210,\n",
        "           DATA31,\n",
        "           DATA32],axis = 1)"
      ],
      "metadata": {
        "id": "ERHueEGOogQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 저장\n",
        "\n",
        "- CSV 저장\n",
        "- SQL 저장"
      ],
      "metadata": {
        "id": "O5T5Jzw9BvWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DATA_DEVICE.to_csv(\"DATA_DATA_DEVICE.csv\")"
      ],
      "metadata": {
        "id": "x3OG7yD8o7i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "connection = sqlite3.connect('./DATA_DATA_DEVICE.sqlite')\n",
        "DATA_DATA_DEVICE.to_sql('DATA_DATA_DEVICE',connection )\n",
        "connection.commit()\n",
        "connection.close()"
      ],
      "metadata": {
        "id": "O3uAIyArrAOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DATA_DEVICE"
      ],
      "metadata": {
        "id": "aW_zj81s7jGN",
        "outputId": "538f7cf3-5b08-4be8-98cb-480fc882e194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        OP_INDEX  DATA_INDEX            DATA_TIME    CSU    STS    FTS  \\\n",
              "0              1           1  2020-07-09 01:50:34  44.80   0.00   0.00   \n",
              "1              1           1  2018-03-14 09:58:58  33.55  10.21  37.16   \n",
              "2              1           1  2020-05-04 02:45:02  45.31   0.00  36.07   \n",
              "3              1           1  2021-05-29 04:26:42   0.00   0.00   0.00   \n",
              "4              1           1  2021-08-12 10:42:54  45.42  26.95  28.02   \n",
              "...          ...         ...                  ...    ...    ...    ...   \n",
              "583067      1075          15  2021-03-04 03:48:51  35.72   0.00  31.84   \n",
              "583068      1075          16  2021-03-04 03:49:51  35.70   0.00  31.86   \n",
              "583069      1075          17  2021-03-04 03:50:51  35.69   0.00  31.83   \n",
              "583070      1075          18  2021-03-04 03:51:51  35.68   0.00  31.86   \n",
              "583071      1075          19  2021-03-04 03:52:51  35.68   0.00  31.85   \n",
              "\n",
              "            FMU   TRO     ANU  RATE  ...  TSU1_BP3_CLX1  TSU1_BP3_CLX2  \\\n",
              "0        488.36  0.00     0.0  -1.0  ...            0.0            0.0   \n",
              "1       3293.63  0.00     0.0  -1.0  ...            0.0            0.0   \n",
              "2       3136.53  0.00     0.0  -1.0  ...            0.0            0.0   \n",
              "3       3524.26  0.00  2400.0   1.0  ...            0.0            0.0   \n",
              "4       2712.63  0.00     0.0   1.0  ...            0.0            0.0   \n",
              "...         ...   ...     ...   ...  ...            ...            ...   \n",
              "583067   629.44  0.47     0.0  -1.0  ...            0.0            0.0   \n",
              "583068   630.25  0.47     0.0  -1.0  ...            0.0            0.0   \n",
              "583069   633.15  0.47     0.0  -1.0  ...            0.0            0.0   \n",
              "583070   629.84  0.47     0.0  -1.0  ...            0.0            0.0   \n",
              "583071   630.79  0.47     0.0  -1.0  ...            0.0            0.0   \n",
              "\n",
              "        TSU2_STATE TSU2_CONTROL  TSU2_BP1_CLX1  TSU2_BP1_CLX2 TSU2_BP2_CLX1  \\\n",
              "0              NaN          NaN            NaN            NaN           NaN   \n",
              "1              NaN          NaN            NaN            NaN           NaN   \n",
              "2              NaN          NaN            NaN            NaN           NaN   \n",
              "3              NaN          NaN            NaN            NaN           NaN   \n",
              "4              NaN          NaN            NaN            NaN           NaN   \n",
              "...            ...          ...            ...            ...           ...   \n",
              "583067         NaN          NaN            NaN            NaN           NaN   \n",
              "583068         NaN          NaN            NaN            NaN           NaN   \n",
              "583069         NaN          NaN            NaN            NaN           NaN   \n",
              "583070         NaN          NaN            NaN            NaN           NaN   \n",
              "583071         NaN          NaN            NaN            NaN           NaN   \n",
              "\n",
              "        TSU2_BP2_CLX2  TSU2_BP3_CLX1  TSU2_BP3_CLX2  \n",
              "0                 NaN            NaN            NaN  \n",
              "1                 NaN            NaN            NaN  \n",
              "2                 NaN            NaN            NaN  \n",
              "3                 NaN            NaN            NaN  \n",
              "4                 NaN            NaN            NaN  \n",
              "...               ...            ...            ...  \n",
              "583067            NaN            NaN            NaN  \n",
              "583068            NaN            NaN            NaN  \n",
              "583069            NaN            NaN            NaN  \n",
              "583070            NaN            NaN            NaN  \n",
              "583071            NaN            NaN            NaN  \n",
              "\n",
              "[583072 rows x 332 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c24eeeae-24c3-4882-9eb2-2d32b0a91569\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OP_INDEX</th>\n",
              "      <th>DATA_INDEX</th>\n",
              "      <th>DATA_TIME</th>\n",
              "      <th>CSU</th>\n",
              "      <th>STS</th>\n",
              "      <th>FTS</th>\n",
              "      <th>FMU</th>\n",
              "      <th>TRO</th>\n",
              "      <th>ANU</th>\n",
              "      <th>RATE</th>\n",
              "      <th>...</th>\n",
              "      <th>TSU1_BP3_CLX1</th>\n",
              "      <th>TSU1_BP3_CLX2</th>\n",
              "      <th>TSU2_STATE</th>\n",
              "      <th>TSU2_CONTROL</th>\n",
              "      <th>TSU2_BP1_CLX1</th>\n",
              "      <th>TSU2_BP1_CLX2</th>\n",
              "      <th>TSU2_BP2_CLX1</th>\n",
              "      <th>TSU2_BP2_CLX2</th>\n",
              "      <th>TSU2_BP3_CLX1</th>\n",
              "      <th>TSU2_BP3_CLX2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-07-09 01:50:34</td>\n",
              "      <td>44.80</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>488.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-03-14 09:58:58</td>\n",
              "      <td>33.55</td>\n",
              "      <td>10.21</td>\n",
              "      <td>37.16</td>\n",
              "      <td>3293.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2020-05-04 02:45:02</td>\n",
              "      <td>45.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>36.07</td>\n",
              "      <td>3136.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-05-29 04:26:42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3524.26</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2400.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-08-12 10:42:54</td>\n",
              "      <td>45.42</td>\n",
              "      <td>26.95</td>\n",
              "      <td>28.02</td>\n",
              "      <td>2712.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583067</th>\n",
              "      <td>1075</td>\n",
              "      <td>15</td>\n",
              "      <td>2021-03-04 03:48:51</td>\n",
              "      <td>35.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.84</td>\n",
              "      <td>629.44</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583068</th>\n",
              "      <td>1075</td>\n",
              "      <td>16</td>\n",
              "      <td>2021-03-04 03:49:51</td>\n",
              "      <td>35.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.86</td>\n",
              "      <td>630.25</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583069</th>\n",
              "      <td>1075</td>\n",
              "      <td>17</td>\n",
              "      <td>2021-03-04 03:50:51</td>\n",
              "      <td>35.69</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.83</td>\n",
              "      <td>633.15</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583070</th>\n",
              "      <td>1075</td>\n",
              "      <td>18</td>\n",
              "      <td>2021-03-04 03:51:51</td>\n",
              "      <td>35.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.86</td>\n",
              "      <td>629.84</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583071</th>\n",
              "      <td>1075</td>\n",
              "      <td>19</td>\n",
              "      <td>2021-03-04 03:52:51</td>\n",
              "      <td>35.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>31.85</td>\n",
              "      <td>630.79</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>583072 rows × 332 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c24eeeae-24c3-4882-9eb2-2d32b0a91569')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c24eeeae-24c3-4882-9eb2-2d32b0a91569 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c24eeeae-24c3-4882-9eb2-2d32b0a91569');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}
